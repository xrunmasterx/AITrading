"""
èˆ†æƒ…åˆ†ææ¨¡å—
åˆ†ææ–°é—»å’Œç¤¾äº¤åª’ä½“çš„æƒ…ç»ªå€¾å‘
"""

import re
from datetime import datetime
from typing import List, Optional, Tuple, Dict
from loguru import logger

from app.models.stock import StockNews


class SentimentAnalyzer:
    """èˆ†æƒ…åˆ†æå™¨"""
    
    def __init__(self):
        # ç®€å•çš„æƒ…ç»ªè¯å…¸ï¼ˆè‹±æ–‡ï¼‰
        self.positive_words = {
            'surge', 'jump', 'gain', 'rise', 'up', 'growth', 'profit', 'beat',
            'exceed', 'strong', 'bullish', 'rally', 'boom', 'soar', 'breakthrough',
            'upgrade', 'outperform', 'buy', 'positive', 'optimistic', 'record',
            'high', 'success', 'win', 'best', 'improve', 'increase', 'expand'
        }
        
        self.negative_words = {
            'drop', 'fall', 'decline', 'down', 'loss', 'miss', 'weak', 'bearish',
            'crash', 'plunge', 'slump', 'tumble', 'downgrade', 'underperform',
            'sell', 'negative', 'pessimistic', 'low', 'fail', 'worst', 'cut',
            'decrease', 'shrink', 'warning', 'risk', 'concern', 'fear', 'trouble'
        }
        
        # ä¸­æ–‡æƒ…ç»ªè¯å…¸
        self.positive_words_cn = {
            'ä¸Šæ¶¨', 'å¤§æ¶¨', 'æš´æ¶¨', 'æ¶¨åœ', 'çªç ´', 'æ–°é«˜', 'åˆ©å¥½', 'å¢é•¿',
            'ç›ˆåˆ©', 'è¶…é¢„æœŸ', 'çœ‹å¥½', 'ä¹°å…¥', 'æ¨è', 'å¼ºåŠ¿', 'åå¼¹', 'å›å‡',
            'åˆ›æ–°', 'é¢†å…ˆ', 'ä¼˜ç§€', 'æˆåŠŸ'
        }
        
        self.negative_words_cn = {
            'ä¸‹è·Œ', 'å¤§è·Œ', 'æš´è·Œ', 'è·Œåœ', 'ç ´ä½', 'æ–°ä½', 'åˆ©ç©º', 'ä¸‹é™',
            'äºæŸ', 'ä¸åŠé¢„æœŸ', 'çœ‹ç©º', 'å–å‡º', 'å‡æŒ', 'å¼±åŠ¿', 'å›è°ƒ', 'ä¸‹æ»‘',
            'é£é™©', 'è­¦å‘Š', 'æ‹…å¿§', 'å¤±è´¥'
        }
    
    def analyze_text(self, text: str) -> Tuple[str, float]:
        """
        åˆ†ææ–‡æœ¬æƒ…ç»ª
        
        Args:
            text: è¦åˆ†æçš„æ–‡æœ¬
            
        Returns:
            (sentiment, score): æƒ…ç»ªç±»å‹å’Œå¾—åˆ†
            - sentiment: positive/negative/neutral
            - score: -1.0 åˆ° 1.0
        """
        if not text:
            return "neutral", 0.0
        
        text_lower = text.lower()
        
        # è®¡ç®—è‹±æ–‡æƒ…ç»ªå¾—åˆ†
        pos_count = sum(1 for word in self.positive_words if word in text_lower)
        neg_count = sum(1 for word in self.negative_words if word in text_lower)
        
        # è®¡ç®—ä¸­æ–‡æƒ…ç»ªå¾—åˆ†
        pos_count += sum(1 for word in self.positive_words_cn if word in text)
        neg_count += sum(1 for word in self.negative_words_cn if word in text)
        
        total = pos_count + neg_count
        if total == 0:
            return "neutral", 0.0
        
        # è®¡ç®—å¾—åˆ† (-1 åˆ° 1)
        score = (pos_count - neg_count) / total
        
        # ç¡®å®šæƒ…ç»ªç±»å‹
        if score > 0.2:
            sentiment = "positive"
        elif score < -0.2:
            sentiment = "negative"
        else:
            sentiment = "neutral"
        
        return sentiment, round(score, 3)
    
    def analyze_news(self, news: StockNews) -> StockNews:
        """
        åˆ†æå•æ¡æ–°é—»çš„æƒ…ç»ª
        
        Args:
            news: æ–°é—»å¯¹è±¡
            
        Returns:
            å¸¦æœ‰æƒ…ç»ªåˆ†æç»“æœçš„æ–°é—»å¯¹è±¡
        """
        # åˆå¹¶æ ‡é¢˜å’Œæ‘˜è¦è¿›è¡Œåˆ†æ
        text = f"{news.title} {news.summary}"
        sentiment, score = self.analyze_text(text)
        
        news.sentiment = sentiment
        news.sentiment_score = score
        
        return news
    
    def analyze_news_list(self, news_list: List[StockNews]) -> List[StockNews]:
        """
        æ‰¹é‡åˆ†ææ–°é—»æƒ…ç»ª
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            å¸¦æœ‰æƒ…ç»ªåˆ†æç»“æœçš„æ–°é—»åˆ—è¡¨
        """
        analyzed = []
        for news in news_list:
            analyzed.append(self.analyze_news(news))
        
        logger.info(f"å®Œæˆ {len(analyzed)} æ¡æ–°é—»æƒ…ç»ªåˆ†æ")
        return analyzed
    
    def get_overall_sentiment(self, news_list: List[StockNews]) -> Dict:
        """
        è·å–æ–°é—»çš„æ•´ä½“æƒ…ç»ªæ¦‚è§ˆ
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            æƒ…ç»ªç»Ÿè®¡ä¿¡æ¯
        """
        if not news_list:
            return {
                "overall": "neutral",
                "score": 0.0,
                "positive_count": 0,
                "negative_count": 0,
                "neutral_count": 0,
                "total": 0
            }
        
        pos_count = 0
        neg_count = 0
        neutral_count = 0
        total_score = 0.0
        
        for news in news_list:
            if news.sentiment == "positive":
                pos_count += 1
            elif news.sentiment == "negative":
                neg_count += 1
            else:
                neutral_count += 1
            
            if news.sentiment_score is not None:
                total_score += news.sentiment_score
        
        total = len(news_list)
        avg_score = total_score / total if total > 0 else 0.0
        
        # ç¡®å®šæ•´ä½“æƒ…ç»ª
        if avg_score > 0.1:
            overall = "positive"
        elif avg_score < -0.1:
            overall = "negative"
        else:
            overall = "neutral"
        
        return {
            "overall": overall,
            "score": round(avg_score, 3),
            "positive_count": pos_count,
            "negative_count": neg_count,
            "neutral_count": neutral_count,
            "total": total,
            "positive_ratio": round(pos_count / total * 100, 1) if total > 0 else 0
        }
    
    def generate_sentiment_summary(self, news_list: List[StockNews]) -> str:
        """
        ç”Ÿæˆèˆ†æƒ…æ‘˜è¦æ–‡æœ¬
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            èˆ†æƒ…æ‘˜è¦å­—ç¬¦ä¸²
        """
        stats = self.get_overall_sentiment(news_list)
        
        if stats['total'] == 0:
            return "æš‚æ— æ–°é—»æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆèˆ†æƒ…åˆ†æã€‚"
        
        sentiment_text = {
            "positive": "åå¤š",
            "negative": "åç©º", 
            "neutral": "ä¸­æ€§"
        }
        
        positive_ratio = stats.get('positive_ratio', 0)
        
        summary = (
            f"èˆ†æƒ…æ¦‚è§ˆ: {sentiment_text.get(stats['overall'], 'ä¸­æ€§')} "
            f"(å¾—åˆ†: {stats['score']:+.2f})\n"
            f"æ–°é—»ç»Ÿè®¡: å…±{stats['total']}æ¡ - "
            f"çœ‹å¤š{stats['positive_count']}æ¡({positive_ratio}%) / "
            f"çœ‹ç©º{stats['negative_count']}æ¡ / "
            f"ä¸­æ€§{stats['neutral_count']}æ¡"
        )
        
        # æ·»åŠ æœ€è¿‘çš„å…³é”®æ–°é—»
        key_news = self._extract_key_news(news_list)
        if key_news:
            summary += "\n\nå…³é”®æ–°é—»:"
            for news in key_news[:3]:
                sentiment_icon = {
                    "positive": "ğŸ“ˆ",
                    "negative": "ğŸ“‰",
                    "neutral": "â–"
                }.get(news.sentiment, "â–")
                summary += f"\n{sentiment_icon} {news.title[:60]}..."
        
        return summary
    
    def _extract_key_news(self, news_list: List[StockNews]) -> List[StockNews]:
        """
        æå–å…³é”®æ–°é—»ï¼ˆæƒ…ç»ªå€¾å‘æ˜æ˜¾çš„ï¼‰
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            å…³é”®æ–°é—»åˆ—è¡¨
        """
        # æŒ‰æƒ…ç»ªå¾—åˆ†ç»å¯¹å€¼æ’åº
        sorted_news = sorted(
            news_list,
            key=lambda x: abs(x.sentiment_score or 0),
            reverse=True
        )
        
        return sorted_news[:5]
    
    def detect_key_events(self, news_list: List[StockNews]) -> List[str]:
        """
        æ£€æµ‹æ–°é—»ä¸­çš„å…³é”®äº‹ä»¶
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            å…³é”®äº‹ä»¶åˆ—è¡¨
        """
        key_events = []
        
        # å…³é”®è¯æ¨¡å¼
        patterns = {
            "è´¢æŠ¥": r"(earnings|è´¢æŠ¥|å­£æŠ¥|å¹´æŠ¥|ä¸šç»©)",
            "æ”¶è´­": r"(acquire|acquisition|merger|æ”¶è´­|å¹¶è´­|åˆå¹¶)",
            "åˆ†æ‹†": r"(split|spinoff|åˆ†æ‹†|æ‹†åˆ†)",
            "æ´¾æ¯": r"(dividend|æ´¾æ¯|åˆ†çº¢|è‚¡æ¯)",
            "è¯„çº§": r"(upgrade|downgrade|rating|è¯„çº§|ä¸Šè°ƒ|ä¸‹è°ƒ)",
            "è£å‘˜": r"(layoff|cut jobs|è£å‘˜|è£å‡)",
            "æ–°äº§å“": r"(launch|release|æ–°äº§å“|å‘å¸ƒ|ä¸Šå¸‚)",
            "ç›‘ç®¡": r"(regulation|SEC|è¯ç›‘ä¼š|ç›‘ç®¡|è°ƒæŸ¥)"
        }
        
        for news in news_list:
            text = f"{news.title} {news.summary}".lower()
            
            for event_type, pattern in patterns.items():
                if re.search(pattern, text, re.IGNORECASE):
                    event = f"[{news.published_at.strftime('%m-%d')}] {event_type}: {news.title[:40]}"
                    if event not in key_events:
                        key_events.append(event)
        
        return key_events[:10]  # æœ€å¤šè¿”å›10ä¸ªå…³é”®äº‹ä»¶


# åˆ›å»ºå…¨å±€å®ä¾‹
def create_sentiment_analyzer() -> SentimentAnalyzer:
    """åˆ›å»ºèˆ†æƒ…åˆ†æå™¨å®ä¾‹"""
    return SentimentAnalyzer()

